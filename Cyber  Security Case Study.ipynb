{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29192872-a546-472b-9773-aac5029d35c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the directory containing the CSV files\n",
    "folder_path = r'XXXXXXXXXXX'\n",
    "\n",
    "# List all files in the folder\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "# Filter the list to include only CSV files\n",
    "csv_files = [file for file in files if file.endswith('.csv')]\n",
    "\n",
    "# Dictionary to store DataFrames\n",
    "dataframes = {}\n",
    "\n",
    "# Loop through each CSV file and store them in the dictionary with names df1, df2, etc.\n",
    "for i, csv_file in enumerate(csv_files, start=1):\n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(folder_path, csv_file)\n",
    "    \n",
    "    # Read the CSV file\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Create a DataFrame name like df1, df2, etc.\n",
    "    df_name = f'df{i}'\n",
    "    \n",
    "    # Store the DataFrame in the dictionary\n",
    "    dataframes[df_name] = data\n",
    "    \n",
    "    # Print the DataFrame name and file name\n",
    "    print(f'DataFrame Name: {df_name}')\n",
    "    print(f'File Name: {csv_file}')\n",
    "    print()  # Add a blank line for better readability\n",
    "\n",
    "# Optionally, you can access and print the first few rows of each DataFrame to verify\n",
    "for df_name, df in dataframes.items():\n",
    "    print(f'DataFrame: {df_name}')\n",
    "    print(df.head())\n",
    "    print()  # Add a blank line for better readability\n",
    "\n",
    "\n",
    "--------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Extract headers from df7\n",
    "df7_headers = dataframes['df7'].columns.tolist()\n",
    "\n",
    "# Assign these headers to df3\n",
    "dataframes['df3'].columns = df7_headers\n",
    "\n",
    "# Identify the original file name for df3\n",
    "df3_file_name = csv_files[2]  # Since df3 corresponds to the third file\n",
    "\n",
    "# Construct the full file path for df3\n",
    "df3_file_path = os.path.join(folder_path, df3_file_name)\n",
    "\n",
    "# Rewrite df3 to the original CSV file\n",
    "dataframes['df3'].to_csv(df3_file_path, index=False)\n",
    "\n",
    "# Verify the rewrite\n",
    "print(f'Rewritten DataFrame: df3 to file {df3_file_name}')\n",
    "print(dataframes['df3'].head())\n",
    "\n",
    "\n",
    "--------------------------------------------------\n",
    "\n",
    "# Assuming 'dataframes' dictionary holds your DataFrames named as 'df1', 'df2', etc.\n",
    "# Combine all DataFrames into one DataFrame with an additional column 'Attack/Normal'\n",
    "\n",
    "# Create a list to hold data with the new Attack/Normal column\n",
    "all_data = []\n",
    "\n",
    "# Append each DataFrame to the list with the new column\n",
    "for df_name, df in dataframes.items():\n",
    "    # Create a copy to avoid modifying the original DataFrames\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Assign \"Normal\" to rows of df7 and \"Attack\" to all others\n",
    "    if df_name == 'df7':\n",
    "        df_copy['Attack/Normal'] = 'Normal'\n",
    "    else:\n",
    "        df_copy['Attack/Normal'] = 'Attack'\n",
    "    \n",
    "    # Append to the list\n",
    "    all_data.append(df_copy)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Print some information to verify\n",
    "print(combined_df.head())\n",
    "print(combined_df['Attack/Normal'].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "--------------------------------------------------\n",
    "\n",
    "# Map 'Attack' to 0 and 'Normal' to 1\n",
    "combined_df['Attack/Normal Binary'] = combined_df['Attack/Normal'].map({'Attack': 0, 'Normal': 1})\n",
    "\n",
    "# Drop the original 'Attack/Normal' column\n",
    "combined_df = combined_df.drop(columns=['Attack/Normal'])\n",
    "\n",
    "# Print the updated DataFrame to verify the changes\n",
    "print(combined_df.head())\n",
    "\n",
    "\n",
    "--------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming 'combined_df' contains your combined DataFrame with the 'Attack/Normal Binary' column as the target variable\n",
    "\n",
    "# Separate features and target\n",
    "X = combined_df.drop(['Attack/Normal Binary'], axis=1)  # Assuming all other columns are features\n",
    "y = combined_df['Attack/Normal Binary']\n",
    "\n",
    "# Split the data into training and testing sets using stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Scale the features (important for many algorithms, including SVM)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train the decision tree model\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions with decision tree model\n",
    "dt_y_pred = dt_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate decision tree model\n",
    "dt_accuracy = accuracy_score(y_test, dt_y_pred)\n",
    "\n",
    "# Initialize and train the SVM model\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions with SVM model\n",
    "svm_y_pred = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate SVM model\n",
    "svm_accuracy = accuracy_score(y_test, svm_y_pred)\n",
    "\n",
    "# Initialize and train the logistic regression model\n",
    "lr_model = LogisticRegression(max_iter=100)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions with logistic regression model\n",
    "lr_y_pred = lr_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate logistic regression model\n",
    "lr_accuracy = accuracy_score(y_test, lr_y_pred)\n",
    "\n",
    "# Compare model performances\n",
    "print(\"Decision Tree Accuracy:\", dt_accuracy)\n",
    "print(\"SVM Accuracy:\", svm_accuracy)\n",
    "print(\"Logistic Regression Accuracy:\", lr_accuracy)\n",
    "\n",
    "\n",
    "--------------------------------------------------\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the directory containing the CSV files\n",
    "folder_path = r'XXXXXXXXXXX'\n",
    "\n",
    "# List all files in the folder\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "# Filter the list to include only CSV files\n",
    "csv_files = [file for file in files if file.endswith('.csv')]\n",
    "\n",
    "# Dictionary to store DataFrames\n",
    "dataframes = {}\n",
    "\n",
    "# Loop through each CSV file and store them in the dictionary with names df1, df2, etc.\n",
    "for i, csv_file in enumerate(csv_files, start=1):\n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(folder_path, csv_file)\n",
    "    \n",
    "    # Read the CSV file\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Create a DataFrame name like df1, df2, etc.\n",
    "    df_name = f'df{i}'\n",
    "    \n",
    "    # Store the DataFrame in the dictionary\n",
    "    dataframes[df_name] = data\n",
    "    \n",
    "    # Print the DataFrame name and file name\n",
    "    print(f'DataFrame Name: {df_name}')\n",
    "    print(f'File Name: {csv_file}')\n",
    "    print()  # Add a blank line for better readability\n",
    "\n",
    "# Extract headers from df7\n",
    "df7_headers = dataframes['df7'].columns.tolist()\n",
    "\n",
    "# Assign these headers to df3\n",
    "dataframes['df3'].columns = df7_headers\n",
    "\n",
    "# Identify the original file name for df3\n",
    "df3_file_name = csv_files[2]  # Since df3 corresponds to the third file\n",
    "\n",
    "# Construct the full file path for df3\n",
    "df3_file_path = os.path.join(folder_path, df3_file_name)\n",
    "\n",
    "# Rewrite df3 to the original CSV file\n",
    "dataframes['df3'].to_csv(df3_file_path, index=False)\n",
    "\n",
    "# Verify the rewrite\n",
    "print(f'Rewritten DataFrame: df3 to file {df3_file_name}')\n",
    "print(dataframes['df3'].head())\n",
    "\n",
    "# Function to extract attack type from file name\n",
    "def extract_attack_type(file_name):\n",
    "    # Extract the part after \"Back_\" and before \".csv\"\n",
    "    start = file_name.find(\"Back_\") + len(\"Back_\")\n",
    "    end = file_name.find(\".csv\")\n",
    "    attack_type = file_name[start:end]\n",
    "    \n",
    "    # If nothing is found, return 'Others'\n",
    "    if attack_type == \"\" or attack_type == \"_of_Attack_Back\":\n",
    "        return \"Others\"\n",
    "    \n",
    "    return attack_type\n",
    "\n",
    "# Create a dictionary for file names\n",
    "file_names = {f'df{i+1}': csv_files[i] for i in range(len(csv_files))}\n",
    "\n",
    "# Function to combine DataFrames\n",
    "def combine_dataframes(dataframes, file_names):\n",
    "    # Create a list to hold data with the new Attack/Normal column\n",
    "    all_data = []\n",
    "\n",
    "    # Append each DataFrame to the list with the new column\n",
    "    for df_name, df in dataframes.items():\n",
    "        # Create a copy to avoid modifying the original DataFrames\n",
    "        df_copy = df.copy()\n",
    "        \n",
    "        # Get the corresponding file name\n",
    "        file_name = file_names[df_name]\n",
    "        \n",
    "        # Extract the attack type from the file name\n",
    "        attack_type = extract_attack_type(file_name)\n",
    "        \n",
    "        # Assign the attack type to the new column\n",
    "        df_copy['Attack/Normal'] = attack_type\n",
    "        \n",
    "        # Append to the list\n",
    "        all_data.append(df_copy)\n",
    "\n",
    "    # Concatenate all DataFrames into a single DataFrame\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "    # Print some information to verify\n",
    "    print(combined_df.head())\n",
    "    print(combined_df['Attack/Normal'].value_counts())\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "# Combine all DataFrames into one\n",
    "combined_df = combine_dataframes(dataframes, file_names)\n",
    "\n",
    "\n",
    "--------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Assuming 'combined_df' is your DataFrame with features and target variable\n",
    "# Replace 'Attack/Normal' with your actual target column name\n",
    "X = combined_df.drop('Attack/Normal', axis=1)\n",
    "y = combined_df['Attack/Normal']\n",
    "\n",
    "# Encode the target variable if it's categorical\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42,stratify=y)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train the logistic regression model\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# Now, we will implement Decision Tree and SVM models for comparison\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize and train the Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions with Decision Tree\n",
    "y_pred_dt = dt_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the Decision Tree model\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(\"\\nDecision Tree Classification Report:\\n\", classification_report(y_test, y_pred_dt, target_names=label_encoder.classes_))\n",
    "\n",
    "# Initialize and train the SVM model\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions with SVM\n",
    "y_pred_svm = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the SVM model\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"\\nSVM Classification Report:\\n\", classification_report(y_test, y_pred_svm, target_names=label_encoder.classes_))\n",
    "\n",
    "\n",
    "--------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "--------------------------------------------------\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
